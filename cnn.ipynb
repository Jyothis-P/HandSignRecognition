{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Successful.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.backend import softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print('Imports Successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, X_dev, Y_dev = np.load('dataset.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.float32(X_train / 255.0)\n",
    "X_test = np.float32(X_test / 255.0)\n",
    "X_dev = np.float32(X_dev / 255.0)\n",
    "\n",
    "m = len(X_train)\n",
    "n = len(X_test)\n",
    "\n",
    "X_train = X_train.reshape((m, 128, 128, 1))\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=24)\n",
    "X_test = X_test.reshape((n, 128, 128, 1))\n",
    "Y_test_categorical = to_categorical(Y_test, num_classes=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Training set: 3978\n",
      "Length of Test set: 497\n",
      "Length of Dev set: 497\n",
      "\n",
      "Shape of training set: (3978, 128, 128, 1)\n",
      "Shape of lables: (3978, 24)\n",
      "\n",
      "Shape of training set: (497, 128, 128, 1)\n",
      "Shape of lables: (497, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of Training set:\", m)\n",
    "print(\"Length of Test set:\", len(X_test))\n",
    "print(\"Length of Dev set:\", len(X_dev))\n",
    "print()\n",
    "print(\"Shape of training set:\", X_train.shape)\n",
    "print(\"Shape of lables:\", Y_train_categorical.shape)\n",
    "print()\n",
    "print(\"Shape of training set:\", X_test.shape)\n",
    "print(\"Shape of lables:\", Y_test_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(arr):\n",
    "    plt.imshow(arr, 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "index = 8\n",
    "show_image(X_train[index].reshape((128, 128)))\n",
    "print(Y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(Conv2D(32, (2, 2), input_shape=(128, 128, 1))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "model.add(Conv2D(32, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "model.add(Conv2D(64, (2, 2))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "  \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(24)) \n",
    "model.add(Activation('softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit( \n",
    "    X_train, \n",
    "    Y_train_categorical,\n",
    "    epochs=10,\n",
    "    validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_history = model.evaluate(X_test,\n",
    "                             Y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES = list(map(chr, range(ord('A'), ord('Z'))))\n",
    "CATEGORIES.pop(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    prediction = model.predict_classes(img.reshape(1, 128, 128, 1))\n",
    "    print(\"Prediction:\", CATEGORIES[np.squeeze(prediction)])\n",
    "    show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 4\n",
    "img_edges = X_test[index].reshape(128, 128)\n",
    "cat = CATEGORIES[Y_test[index]]\n",
    "prediction = model.predict_classes(X_test[index].reshape(1, 128, 128, 1))\n",
    "\n",
    "print(\"Original:\", cat)\n",
    "print(\"Prediction:\", CATEGORIES[np.squeeze(prediction)])\n",
    "show_image(img_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mask_skin(frame, visualize_steps= False):\n",
    "    converted2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    converted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # Convert from RGB to HSV\n",
    "    \n",
    "    lowerBoundary = np.array([0,40,30],dtype=\"uint8\")\n",
    "    upperBoundary = np.array([43,255,254],dtype=\"uint8\")\n",
    "    \n",
    "    skinMask = cv2.inRange(converted, lowerBoundary, upperBoundary)\n",
    "    skinMask = cv2.addWeighted(skinMask,0.5,skinMask,0.5,0.0)\n",
    "    skinMask = cv2.medianBlur(skinMask, 5)\n",
    "    \n",
    "    skin = cv2.bitwise_and(converted2, converted2, mask = skinMask)\n",
    "    \n",
    "    if visualize_steps:\n",
    "        show_image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        show_image(converted)\n",
    "        show_image(converted2)\n",
    "        show_image(skinMask)\n",
    "    \n",
    "    return skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(img_array, visualize_steps= False):\n",
    "    frame = cv2.resize(img_array, (128, 128))\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    skin = mask_skin(frame, visualize_steps)\n",
    "    \n",
    "    edges = cv2.Canny(skin,60,60)\n",
    "    \n",
    "    if visualize_steps:\n",
    "        print(\"path:\", path)\n",
    "        print(\"shape:\", img_array.shape)\n",
    "        show_image(skin)\n",
    "        show_image(edges)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = r'C:\\Users\\jyoth\\OneDrive\\Pictures\\Camera Roll\\five.jpg'\n",
    "image = cv2.imread(p)\n",
    "edges = process_image(image)\n",
    "predict(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # video capture source camera (Here webcam of laptop) \n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read() # return a single frame in variable `frame`\n",
    "    cv2.imshow('img1',frame) #display the captured image\n",
    "    if cv2.waitKey(1) & 0xFF == ord('y'): #save on pressing 'y'\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "edges = process_image(frame)\n",
    "predict(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('mod')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mod')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy']) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit( \n",
    "    X_train, \n",
    "    Y_train_categorical,\n",
    "    epochs=10,\n",
    "    validation_split=0.2) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_history = model.evaluate(X_test,\n",
    "                             Y_test_categorical)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CATEGORIES = list(map(chr, range(ord('A'), ord('Z'))))\n",
    "CATEGORIES.pop(9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    prediction = model.predict_classes(img.reshape(1, 128, 128, 1))\n",
    "    print(\"Prediction:\", CATEGORIES[np.squeeze(prediction)])\n",
    "    show_image(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = 4\n",
    "img_edges = X_test[index].reshape(128, 128)\n",
    "cat = CATEGORIES[Y_test[index]]\n",
    "prediction = model.predict_classes(X_test[index].reshape(1, 128, 128, 1))\n",
    "\n",
    "print(\"Original:\", cat)\n",
    "print(\"Prediction:\", CATEGORIES[np.squeeze(prediction)])\n",
    "show_image(img_edges)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mask_skin(frame, visualize_steps= False):\n",
    "    converted2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    converted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # Convert from RGB to HSV\n",
    "    \n",
    "    lowerBoundary = np.array([0,40,30],dtype=\"uint8\")\n",
    "    upperBoundary = np.array([43,255,254],dtype=\"uint8\")\n",
    "    \n",
    "    skinMask = cv2.inRange(converted, lowerBoundary, upperBoundary)\n",
    "    skinMask = cv2.addWeighted(skinMask,0.5,skinMask,0.5,0.0)\n",
    "    skinMask = cv2.medianBlur(skinMask, 5)\n",
    "    \n",
    "    skin = cv2.bitwise_and(converted2, converted2, mask = skinMask)\n",
    "    \n",
    "    if visualize_steps:\n",
    "        show_image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        show_image(converted)\n",
    "        show_image(converted2)\n",
    "        show_image(skinMask)\n",
    "    \n",
    "    return skin"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_image(img_array, visualize_steps= False):\n",
    "    frame = cv2.resize(img_array, (128, 128))\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    skin = mask_skin(frame, visualize_steps)\n",
    "    \n",
    "    edges = cv2.Canny(skin,60,60)\n",
    "    \n",
    "    if visualize_steps:\n",
    "        print(\"path:\", path)\n",
    "        print(\"shape:\", img_array.shape)\n",
    "        show_image(skin)\n",
    "        show_image(edges)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    return edges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p = r'C:\\Users\\jyoth\\OneDrive\\Pictures\\Camera Roll\\five.jpg'\n",
    "image = cv2.imread(p)\n",
    "edges = process_image(image)\n",
    "predict(edges)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # video capture source camera (Here webcam of laptop) \n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('img1',frame) #display the captured image\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "edges = process_image(frame)\n",
    "predict(edges)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3182 samples, validate on 796 samples\n",
      "Epoch 1/10\n",
      "3182/3182 [==============================] - 20s 6ms/sample - loss: 2.3123 - accuracy: 0.3246 - val_loss: 0.9999 - val_accuracy: 0.7148\n",
      "Epoch 2/10\n",
      "3182/3182 [==============================] - 18s 6ms/sample - loss: 1.0545 - accuracy: 0.6666 - val_loss: 0.4041 - val_accuracy: 0.9095\n",
      "Epoch 3/10\n",
      "3182/3182 [==============================] - 20s 6ms/sample - loss: 0.6440 - accuracy: 0.7813 - val_loss: 0.1887 - val_accuracy: 0.9510\n",
      "Epoch 4/10\n",
      "3182/3182 [==============================] - 18s 6ms/sample - loss: 0.4453 - accuracy: 0.8495 - val_loss: 0.1422 - val_accuracy: 0.9623\n",
      "Epoch 5/10\n",
      "3182/3182 [==============================] - 18s 6ms/sample - loss: 0.3662 - accuracy: 0.8768 - val_loss: 0.1046 - val_accuracy: 0.9711\n",
      "Epoch 6/10\n",
      "3182/3182 [==============================] - 19s 6ms/sample - loss: 0.3124 - accuracy: 0.8953 - val_loss: 0.0805 - val_accuracy: 0.9799\n",
      "Epoch 7/10\n",
      "3182/3182 [==============================] - 19s 6ms/sample - loss: 0.2662 - accuracy: 0.9114 - val_loss: 0.0683 - val_accuracy: 0.9812\n",
      "Epoch 8/10\n",
      "3182/3182 [==============================] - 20s 6ms/sample - loss: 0.2494 - accuracy: 0.9107 - val_loss: 0.0516 - val_accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "3182/3182 [==============================] - 19s 6ms/sample - loss: 0.2406 - accuracy: 0.9177 - val_loss: 0.0591 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "3182/3182 [==============================] - 19s 6ms/sample - loss: 0.2040 - accuracy: 0.9290 - val_loss: 0.0708 - val_accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( \n",
    "    X_train, \n",
    "    Y_train_categorical,\n",
    "    epochs=10,\n",
    "    validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 [==============================] - 1s 1ms/sample - loss: 0.0848 - accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "eval_history = model.evaluate(X_test,\n",
    "                             Y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES = list(map(chr, range(ord('A'), ord('Z'))))\n",
    "CATEGORIES.pop(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    prediction = model.predict_classes(img.reshape(1, 128, 128, 1))\n",
    "    print(\"Prediction:\", CATEGORIES[np.squeeze(prediction)])\n",
    "    show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0e63260fb82e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg_edges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCATEGORIES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "img_edges = X_test[index].reshape(128, 128)\n",
    "cat = CATEGORIES[Y_test[index]]\n",
    "prediction = model.predict_classes(X_test[index].reshape(1, 128, 128, 1))\n",
    "\n",
    "print(\"Original:\", cat)\n",
    "print(\"Prediction:\", CATEGORIES[np.squeeze(prediction)])\n",
    "show_image(img_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_skin(frame, visualize_steps= False):\n",
    "    converted2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    converted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # Convert from RGB to HSV\n",
    "    \n",
    "    lowerBoundary = np.array([0,40,30],dtype=\"uint8\")\n",
    "    upperBoundary = np.array([43,255,254],dtype=\"uint8\")\n",
    "    \n",
    "    skinMask = cv2.inRange(converted, lowerBoundary, upperBoundary)\n",
    "    skinMask = cv2.addWeighted(skinMask,0.5,skinMask,0.5,0.0)\n",
    "    skinMask = cv2.medianBlur(skinMask, 5)\n",
    "    \n",
    "    skin = cv2.bitwise_and(converted2, converted2, mask = skinMask)\n",
    "    \n",
    "    if visualize_steps:\n",
    "        show_image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        show_image(converted)\n",
    "        show_image(converted2)\n",
    "        show_image(skinMask)\n",
    "    \n",
    "    return skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_array, visualize_steps= False):\n",
    "    frame = cv2.resize(img_array, (128, 128))\n",
    "    # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    skin = mask_skin(frame, visualize_steps)\n",
    "    \n",
    "    edges = cv2.Canny(skin,60,60)\n",
    "    \n",
    "    if visualize_steps:\n",
    "        print(\"path:\", path)\n",
    "        print(\"shape:\", img_array.shape)\n",
    "        show_image(skin)\n",
    "        show_image(edges)\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: E\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = r'C:\\Users\\jyoth\\OneDrive\\Pictures\\Camera Roll\\five.jpg'\n",
    "image = cv2.imread(p)\n",
    "edges = process_image(image)\n",
    "predict(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Y\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASHklEQVR4nO3db6wc1XnH8e+vdgyBFNmGghybFiNZaWnUFrAik0QVgqQBijCRQHKElNuUymqVtiRUCnZ5EfVdaaOERmpJLSBxK8KfElpbKC21HKr0DS73hgYMxrETWrjBwSACqRKpws3TFzMbxuvZv/Nn597z+0jW7s7O7hyfu/PMc86cmaOIwMzS9XOzLoCZzZaDgFniHATMEucgYJY4BwGzxDkImCWusSAg6SpJhyUdlbSjqe2YWTVqYpyApBXAd4APA4vAk8DHIuK52jdmZpWsbOh73wccjYjvAUh6ANgKlAYBSR6xZNa81yLiF/oXNtUcWA+8VHi9mC/7GUnbJc1Lmm+oDGZ2sv8uW9hUJqCSZScd7SNiF7ALnAmYzVJTmcAicH7h9Qbg5Ya2ZWYVNBUEngQ2SdooaRWwDdjb0LbMrIJGmgMRcULSHwKPASuAeyPi2Sa2ZWbVNHKKcOJCuE/ArA0LEbG5f6FHDJolzkHALHEOAmaJcxAwS5yDgFniHATMEucgYJY4BwGzxDkImCXOQcAscQ4CZolzEDBLnIOAWeIcBMwS5yBgljgHAbPEOQiYJc5BwCxxDgJmiXMQMEucg4BZ4hwEzBLXiSBw6aWX0oVbn5ulqBNBwMxmp1OTj0QEUtlcpmZWg3onH5F0vqTHJR2S9KykW/LlayXtk3Qkf1xTpdRm1qwqzYETwJ9ExK8AW4BPSroI2AHsj4hNwP78tZl11NRBICKORcS38uf/AxwC1gNbgd35aruB66sW0syaU8usxJIuAC4GDgDnRcQxyAKFpHMHfGY7sL2O7ZvZ9CqfHZD0LuBrwKci4kfjfi4idkXE5ojY3DtF6E5Bs/ZVCgKS3kEWAO6LiEfyxa9IWpe/vw44Pup7FhYWHADMZqTK2QEB9wCHIuLzhbf2AnP58zlgz/TFM7OmTT1OQNIHgX8HngF+mi/+U7J+gYeAXwReBG6MiNdHfNfsByuYLX+l4wQ6NVjIzBpV72AhM1seHATMEucgYJY4BwGzxDkImCXOQcAscQ4CZolzEDBLnIOAWeIcBMwS5yBgljgHAbPEOQiYJc5BwCxxDgJmiXMQMEucg4BZ4hwEzBLnIGCWOAcBs8Q5CJglzkHALHEOAmaJcxAwS5yDgFni6piVeIWkpyQ9mr/eKOmApCOSHpS0qnoxLRURcco/a1YdmcAtwKHC6zuAL0TEJuCHwM01bMPMGlJ1avINwG8Dd+evBVwBPJyvshu4vso2LE2SfjZdvTOCZlXNBO4EPsPbsxKfDbwRESfy14vA+rIPStouaV7SfMUymFkFUwcBSdcCxyNiobi4ZNXSEB4RuyJic9ksqWY9vWzAmrOywmc/AFwn6RrgdOAsssxgtaSVeTawAXi5ejHNrClTZwIRsTMiNkTEBcA24BsRcRPwOHBDvtocsKdyKc2sMU2ME7gNuFXSUbI+gnsa2IYlwh2CzVMXKlnS7AthndD7PRbPDPS4f6CyhbI+OI8YtE7zjt88BwGzxFU5O2DWGDcD2uMgYJ3Q3zdV1idgzXBzwCxxzgSsU/pTf0mnnDGwejkTMEucg4B1iq8YbJ+bAzZzEeFUf4acCZglzpmAzVyx86+4zNrhTMAscc4EbOaG9Qm4v6B5zgTMEucgYI0Zdaqvdzqw1yfgU4Oz4eaA1aasc887dvc5EzBLnDMBq2TUJb/DOvV6n3W2MFvOBMwS50zAJjLtoJ6yKwF96q8bnAnY2PpT/1E78aA0v/9MgJsDs+UgYJY4NwdspKbv91f2nb6RSHucCZglzpmAja3KUXlUh6CP/LNTKROQtFrSw5Kel3RI0mWS1kraJ+lI/rimrsJa9/R38I3bGdivv6Ox99qdhs2r2hz4K+BfIuKXgV8HDgE7gP0RsQnYn782s46aei5CSWcB3wYujMKXSDoMXB4RxyStA/4tIt4z4rsc7jtsWKpevNR33JR+ktTflxLXqva5CC8EXgW+LOkpSXdLOhM4LyKOAeSP55Z9WNJ2SfOS5iuUwcwqqhIEVgKXAHdFxMXAj5kg9Y+IXRGxuSwyWTcUL/UtHu3bbKc7C2helSCwCCxGxIH89cNkQeGVvBlA/ni8WhHNrElTB4GI+AHwkqRee/9K4DlgLzCXL5sD9lQqoXVKWS/+IL2soex6g+LnhmUWPjvQvKrjBP4IuE/SKuB7wCfIAstDkm4GXgRurLgNm5FxOvyGjSYcN5UvCwhuBrRn6rMDtRbCZwc6bdogUMe2fHagVqVnBzxi0CbSv5NOuoOW7dSjsglnB83ytQNmiXMmYJXVcaT2UX52HASWmUF9PG3uZE7flxY3B8wS50xgmZqk863K945SlhWUdS46e5gdZwJmiXMmkIhBI/TqPPKOO/Jv0qsOJ13fJuNMwCxxzgSWqWFHzbIrAus4uo4zA1EXRqjayRwElpn+1HlUMCibCmxQ+j1oCO+gHX3URUK+12A3uDlgljhnAstUWUYw7oSh0x6NyzKHcdabZltWH2cCZolzJrDMjToqD/vMOMtH3Ubcus9BICF1drqNe4+BcUx68xHfY6Bebg6YJc6ZQCLKTgdOO7X4qM/WcaMRa48zAbPEORNIyLinDfvXn9ag7/dVhN3iINCCcUfLtWXSYcPFdSbZWSf5Pw46i+Gg0Dw3B8wS50ygRdOcs2/SuJ2FTY3sG3eb1ixnAmaJcyaQuEk7C+vcZpXPuyOxPpUyAUmflvSspIOS7pd0uqSNkg5IOiLpwXyKMjPrqKmDgKT1wB8DmyPivcAKYBtwB/CFiNgE/BC4uY6CWrNmOf34oHL09Jenf7p0q6Zqn8BK4J2SVgJnAMeAK8imKQfYDVxfcRtLXu8H2/sxF593Tf+NQLpYRqtXlanJvw98jmzm4WPAm8AC8EZEnMhXWwTWl31e0nZJ85Lmpy2DmVVXpTmwBtgKbATeDZwJXF2yaumhJCJ2RcTmsllSbbb6U+06M4Led1X5vi5nUktRlebAh4AXIuLViHgLeAR4P7A6bx4AbABerlhGM2tQlSDwIrBF0hnKDhtXAs8BjwM35OvMAXuqFXH5KB5hl0LHVq+M/X0aVY/iZZnGID7aN69Kn8ABsg7AbwHP5N+1C7gNuFXSUeBs4J4ayrnsFHeopZLa1h0Qit87zjatGerCj0/S7AvRsq5dVDSppmYxmnT7S6nOOmChrA/OIwZnrGvXE4xr2JiCYam+d9ru8bUDZolzJtARS3U8fNlRv/j/GPc+BdNudynWWdc4CFhtxrkYadZ9CXYqNwfMEudMwGo37PZldR/9PRdBdc4EzBLnIDBj/UfL5TQuvu0rEpdLvbXNQcAscQ4CM5LKUNhJrhOouh2bjjsGZyyVjq02RkZ67MB0nAmYJc5BwFrXVgeeOwrH4yBgljgHAWtVG+30VDpd6+IgYDNTd7re/33FcRc2mIOAWeJ8irBDUjliNTX12bBThD5tOJgzAbPEORPoiBSPUE0NIOqvS/cLDOcgYJ3QdLru0YSDuTlgljgHAZu5Wd6y3BwEzJKXXJ9Af5tw1BHBbcd2td03YGNkApLulXRc0sHCsrWS9kk6kj+uyZdL0hclHZX0tKRLmiy8mVU3TnPgK8BVfct2APsjYhOwP38N2dTkm/J/24G76ilmffrHlfc/H2fcedk8gktxbsEuaXu8/3K6jVtVI4NARHwTeL1v8VZgd/58N3B9YfnfReYJsmnK19VV2KoG7azT3v2mf9be/iAyzo/MweNkw+6z2FT9pF7v03YMnhcRxwDyx3Pz5euBlwrrLebLTiFpu6R5SfNTlsHMalB3x2BZPlcaYiNiF9lU5q3OSjxuyjnOesOOHsVRauN0dnmce7kmb7vmTsLMtJnAK700P388ni9fBM4vrLcBeHn64plZ06YNAnuBufz5HLCnsPzj+VmCLcCbvWbDLI3b5iv2EQwzqA+g+F7/c5tMWd01dX+A1O87MLI5IOl+4HLgHEmLwGeBPwceknQz8CJwY77614FrgKPAT4BPNFDmiQ2bFqu405ftsGU/jGGTbI7LKX83pfh3UReiX1t9AmUz4o468k8aBIYFknHb/Sn+EAcZNLNxE3WTwIzJCxGxuX9hUiMGx+2sG5UdFNcrfveg7x33Cjbv/Kcq/s1G/U2q1l+qTQJfO2CWuKQyARh+a6viUWCcdL3/O/u/30f0erVx27AU7zvgTMAsccllAj3Dzhj0lhcfy7KFKkeJFI4wdZnlFZ8pZATJBoGeQZ1Bg84A1PVjGNaksPHVWW9lHcJ13xG5i9wcMEtc8pkAjNcZ1PT4dRut6U7XYacjl/OpQ2cCZolzJlBBnZnDcm5zNqGpDrsU/wYOAhWM+4MpuzlGiuej6zLpZdo2nJsDZolzJlCijk6gslOPbXY4Lndlp/BsOs4EzBLnTKCgqYEn1hzXcXXOBBriH6ctFQ4CZolzEDBLnIOAWeIcBMwS5yBgljgHAbPEOQiYJc5BwCxxDgJmiRsZBCTdK+m4pIOFZX8p6XlJT0v6R0mrC+/tlHRU0mFJH2mq4GZWj3Eyga8AV/Ut2we8NyJ+DfgOsBNA0kXANuBX88/8jaQVtZXWzGo3MghExDeB1/uW/WtEnMhfPkE2BTnAVuCBiPjfiHiBbGLS99VYXjOrWR19Ar8L/HP+fD3wUuG9xXzZKSRtlzQvab6GMpjZlCpdSizpduAEcF9vUclqpXd7iIhdwK78e3xHCLMZmToISJoDrgWujLdv67IInF9YbQPw8vTFM7OmTdUckHQVcBtwXUT8pPDWXmCbpNMkbQQ2Af9RvZhm1pSRmYCk+4HLgXMkLQKfJTsbcBqwL795xhMR8fsR8aykh4DnyJoJn4yI/2uq8GZWnbpwg0b3CZi1YiEiNvcv9IhBs8Q5CJglzkHALHEOAmaJcxAwS5yDgFniHATMEteVacheA36cP87aObgcRS7HyZZyOX6pbGEnBgsBSJovG8jgcrgcLkez5XBzwCxxDgJmietSENg16wLkXI6TuRwnW3bl6EyfgJnNRpcyATObAQcBs8R1IghIuiqfp+CopB0tbfN8SY9LOiTpWUm35MvXSton6Uj+uKal8qyQ9JSkR/PXGyUdyMvxoKRVLZRhtaSH8zklDkm6bBb1IenT+d/koKT7JZ3eVn0MmGejtA6U+WL+u31a0iUNl6OZ+T4iYqb/gBXAd4ELgVXAt4GLWtjuOuCS/PnPk82fcBHwF8COfPkO4I6W6uFW4KvAo/nrh4Bt+fMvAX/QQhl2A7+XP18FrG67PsjuTv0C8M5CPfxOW/UB/CZwCXCwsKy0DoBryO60LWALcKDhcvwWsDJ/fkehHBfl+81pwMZ8f1ox9raa/mGN8Z+9DHis8HonsHMG5dgDfBg4DKzLl60DDrew7Q3AfuAK4NH8R/Va4Q9+Uh01VIaz8p1PfctbrQ/evm39WrIRrY8CH2mzPoAL+na+0joA/hb4WNl6TZSj772PAvflz0/aZ4DHgMvG3U4XmgNjz1XQFEkXABcDB4DzIuIYQP54bgtFuBP4DPDT/PXZwBvx9gQvbdTJhcCrwJfzZsndks6k5fqIiO8DnwNeBI4BbwILtF8fRYPqYJa/3anm+yjThSAw9lwFjWxcehfwNeBTEfGjtrZb2P61wPGIWCguLlm16TpZSZZ+3hURF5Ndy9FK/0xR3t7eSpbWvhs4E7i6ZNUunNueyW+3ynwfZboQBGY2V4Gkd5AFgPsi4pF88SuS1uXvrwOON1yMDwDXSfov4AGyJsGdwGpJvQu82qiTRWAxIg7krx8mCwpt18eHgBci4tWIeAt4BHg/7ddH0aA6aP23W5jv46bIc/+q5ehCEHgS2JT3/q4im9B0b9MbVXav9HuAQxHx+cJbe4G5/PkcWV9BYyJiZ0RsiIgLyP7v34iIm4DHgRtaLMcPgJckvSdfdCXZreNbrQ+yZsAWSWfkf6NeOVqtjz6D6mAv8PH8LMEW4M1es6EJjc330WQnzwQdINeQ9c5/F7i9pW1+kCxlehr4z/zfNWTt8f3AkfxxbYv1cDlvnx24MP9DHgX+ATithe3/BjCf18k/AWtmUR/AnwHPAweBvyfr9W6lPoD7yfoi3iI7wt48qA7I0vC/zn+3zwCbGy7HUbK2f+/3+qXC+rfn5TgMXD3Jtjxs2CxxXWgOmNkMOQiYJc5BwCxxDgJmiXMQMEucg4BZ4hwEzBL3/39uU099E5IcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) # video capture source camera (Here webcam of laptop) \n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('img1',frame) #display the captured image\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "edges = process_image(frame)\n",
    "predict(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: mod\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}